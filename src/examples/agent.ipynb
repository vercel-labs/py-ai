{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be7c7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import random\n",
    "\n",
    "from proto_sdk import (\n",
    "    Agent,\n",
    "    LanguageModel,\n",
    "    Message,\n",
    "    TextPart,\n",
    "    ToolCallPart,\n",
    "    Toolkit,\n",
    "    OpenAIProvider,\n",
    "    AnthropicProvider,\n",
    ")\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9d4d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up toolkit with decorator\n",
    "toolkit = Toolkit()\n",
    "\n",
    "\n",
    "@toolkit.tool\n",
    "def roll_dice(num_dice: int = 1, sides: int = 6) -> dict:\n",
    "    \"\"\"Roll one or more dice with a specified number of sides.\"\"\"\n",
    "    rolls = [random.randint(1, sides) for _ in range(num_dice)]\n",
    "    return {\"rolls\": rolls, \"total\": sum(rolls)}\n",
    "\n",
    "\n",
    "@toolkit.tool\n",
    "async def get_weather(location: str, unit: str = \"celsius\") -> dict:\n",
    "    \"\"\"Get the current weather for a location.\"\"\"\n",
    "    # Simulate async API call\n",
    "    await asyncio.sleep(0.1)\n",
    "    return {\"location\": location, \"temperature\": 22, \"unit\": unit}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5013dbe",
   "metadata": {},
   "outputs": [],
   "source": "api_key = os.getenv(\"AI_GATEWAY_API_KEY\")\nif not api_key:\n    raise ValueError(\"Set AI_GATEWAY_API_KEY environment variable\")\n\n# Create agent with Anthropic provider via Vercel AI Gateway\n# You can also use:\n#   - AnthropicProvider(api_key=os.getenv(\"ANTHROPIC_API_KEY\")) for direct Anthropic API\n#   - OpenAIProvider(model=\"gpt-4o\", api_key=os.getenv(\"OPENAI_API_KEY\")) for OpenAI\n\nprovider = AnthropicProvider(\n    model=\"anthropic/claude-sonnet-4\",\n    base_url=\"https://ai-gateway.vercel.sh\",\n    api_key=api_key,\n    api_key_env_var=\"AI_GATEWAY_API_KEY\",  # Stored in config for deserialization\n)\n\nagent = Agent(\n    language_model=LanguageModel(provider),\n    toolkit=toolkit,\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2ba61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add user message\n",
    "agent.memory.push(Message(\n",
    "    role=\"user\",\n",
    "    parts=[TextPart(text=\"Roll 2 dice, then tell me the weather in Tokyo.\")]\n",
    "))\n",
    "\n",
    "# Run agent and stream output\n",
    "print(\"Agent output:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "async for msg in agent.run():\n",
    "    if msg.text_delta:\n",
    "        print(msg.text_delta, end=\"\", flush=True)\n",
    "\n",
    "    if msg.is_complete:\n",
    "        for p in msg.parts:\n",
    "            if isinstance(p, ToolCallPart):\n",
    "                print(f\"\\n[Tool: {p.tool_name}({p.tool_args})]\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da42dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show final memory state\n",
    "print(\"Final messages in memory:\")\n",
    "for m in agent.memory.messages:\n",
    "    print(f\"  {m.role}: {[type(p).__name__ for p in m.parts]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b6d126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View serialized state - notice provider_name and provider_config\n",
    "agent.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4625f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View module hierarchy\n",
    "agent.named_modules()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "## Serialization & Deserialization\n",
    "\n",
    "Now let's test saving and restoring agent state. This simulates persisting an agent to disk and resuming later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6g7h8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Serialize agent state to JSON (could be saved to disk)\n",
    "state_json = json.dumps(agent.state_dict(), indent=2)\n",
    "print(\"Serialized state:\")\n",
    "print(state_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i9j0k1l2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new agent with the same toolkit\n",
    "# Note: Tools must be re-registered since functions can't be serialized\n",
    "toolkit2 = Toolkit()\n",
    "\n",
    "@toolkit2.tool\n",
    "def roll_dice(num_dice: int = 1, sides: int = 6) -> dict:\n",
    "    \"\"\"Roll one or more dice with a specified number of sides.\"\"\"\n",
    "    rolls = [random.randint(1, sides) for _ in range(num_dice)]\n",
    "    return {\"rolls\": rolls, \"total\": sum(rolls)}\n",
    "\n",
    "@toolkit2.tool\n",
    "async def get_weather(location: str, unit: str = \"celsius\") -> dict:\n",
    "    \"\"\"Get the current weather for a location.\"\"\"\n",
    "    await asyncio.sleep(0.1)\n",
    "    return {\"location\": location, \"temperature\": 22, \"unit\": unit}\n",
    "\n",
    "# Create agent2 with a dummy provider (will be replaced by load_state_dict)\n",
    "agent2 = Agent(\n",
    "    language_model=LanguageModel(AnthropicProvider(api_key=api_key)),\n",
    "    toolkit=toolkit2,\n",
    ")\n",
    "\n",
    "print(f\"agent2 memory before load: {len(agent2.memory.messages)} messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m3n4o5p6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved state into agent2\n",
    "saved_state = json.loads(state_json)\n",
    "agent2.load_state_dict(saved_state)\n",
    "\n",
    "print(f\"agent2 memory after load: {len(agent2.memory.messages)} messages\")\n",
    "print(f\"agent2 provider: {agent2.llm._provider.provider_name()}\")\n",
    "print(f\"agent2 model: {agent2.llm._provider._model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q7r8s9t0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show that agent2 has the conversation history\n",
    "print(\"agent2 conversation history:\")\n",
    "for m in agent2.memory.messages:\n",
    "    print(f\"  {m.role}: {[type(p).__name__ for p in m.parts]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u1v2w3x4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the conversation with agent2!\n",
    "agent2.memory.push(Message(\n",
    "    role=\"user\",\n",
    "    parts=[TextPart(text=\"What was my dice roll total? And can you roll again?\")]\n",
    "))\n",
    "\n",
    "print(\"Continuing conversation with agent2:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "async for msg in agent2.run():\n",
    "    if msg.text_delta:\n",
    "        print(msg.text_delta, end=\"\", flush=True)\n",
    "    if msg.is_complete:\n",
    "        for p in msg.parts:\n",
    "            if isinstance(p, ToolCallPart):\n",
    "                print(f\"\\n[Tool: {p.tool_name}({p.tool_args})]\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y5z6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify agent2 now has more messages\n",
    "print(f\"agent2 final message count: {len(agent2.memory.messages)}\")\n",
    "print(\"\\nFull conversation:\")\n",
    "for m in agent2.memory.messages:\n",
    "    if m.role == \"user\":\n",
    "        text = next((p.text for p in m.parts if isinstance(p, TextPart)), \"\")\n",
    "        print(f\"  USER: {text[:60]}...\" if len(text) > 60 else f\"  USER: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939302fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}